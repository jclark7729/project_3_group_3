{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AJ7J4n-1wuP"
      },
      "source": [
        "Our application allows for patients to input some symptoms into a symptom tracker.  This information is then associated to some possible diagnoses.\n",
        "\n",
        "Some new technologies we used (we did not cover in our boot camp) are:\n",
        "1. **SentencePiece** is a supplement to our NLTK.  This supplement is needed to assist in translating medical terms or more complex words.\n",
        "2. **%%capture** is unique to Google Colab.  This allows for the !pip installs to run without generating all the responses, which clutter up the application.\n",
        "3. **sqlite3** is a lightweight database management system.  Given that we are dealing with large dataset(s) for our model, sqlite allows our application to store and retreive data using SQL (structured query language.)  We are using this for efficiency and speed of use.\n",
        "4. **Flagging** we added this feature to our gradio interface.  It is used to collect information from users about how the application is working. It is part of improving the model over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k4s96ikCWJ2D"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (5.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (4.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.9.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio-client==1.7.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
            "Collecting sklearn"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py egg_info did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [15 lines of output]\n",
            "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
            "      rather than 'sklearn' for pip commands.\n",
            "      \n",
            "      Here is how to fix this error in the main use cases:\n",
            "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
            "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
            "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
            "      - if the 'sklearn' package is used by one of your dependencies,\n",
            "        it would be great if you take some time to track which package uses\n",
            "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
            "      - as a last resort, set the environment variable\n",
            "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
            "      \n",
            "      More information is available at\n",
            "      https://github.com/scikit-learn/sklearn-pypi-package\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "× Encountered error while generating package metadata.\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n",
            "Requirement already satisfied: nltk in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (2024.7.24)\n",
            "Requirement already satisfied: tqdm in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: transformers in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (4.48.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (2024.7.24)\n",
            "Requirement already satisfied: requests in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (72.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (0.2.0)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: tensorflow_hub in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow_hub) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow_hub) (4.25.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (24.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (72.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.7.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.4.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.1.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement tensorflow_text (from versions: none)\n",
            "ERROR: No matching distribution found for tensorflow_text\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\n",
            "ERROR: No matching distribution found for sqlite3\n"
          ]
        }
      ],
      "source": [
        "# Our pip installs needed to run our application.  Note the %%capture being used is for google colab only.\n",
        "# Remove if you are going to run this in VSCode.\n",
        "\n",
        "\n",
        "!pip install gradio\n",
        "!pip install sklearn\n",
        "!pip install nltk\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentencepiece\n",
        "!pip install tensorflow --upgrade\n",
        "!pip install tensorflow_hub\n",
        "!pip install tensorflow_text\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install sqlite3\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 4,
=======
      "execution_count": 2,
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "metadata": {
        "id": "DBhc0mcPWqf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (72.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jclar\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jclar\\anaconda3\\envs\\dev\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\jclar\\anaconda3\\envs\\dev\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\jclar\\anaconda3\\envs\\dev\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:70\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 70\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentencepiece\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_text\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jclar\\anaconda3\\envs\\dev\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
            "File \u001b[1;32mc:\\Users\\jclar\\anaconda3\\envs\\dev\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:85\u001b[0m\n\u001b[0;32m     83\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     87\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     88\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\jclar\\anaconda3\\envs\\dev\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 70, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
          ]
        }
      ],
      "source": [
        "# Imports needed for this application\n",
<<<<<<< HEAD
        "!pip install tensorflow \n",
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
        "import torch\n",
        "import sentencepiece\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub\n",
        "import tensorflow_text\n",
        "import numpy as np\n",
        "import sqlite3\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 3,
=======
      "source": [
        "# List versions of the imports\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"SentencePiece Version:\", sentencepiece.__version__)\n",
        "print(\"TensorFlow Version:\", tensorflow.__version__)\n",
        "print(\"TensorFlow Hub Version:\", tensorflow_hub.__version__)\n",
        "print(\"TensorFlow Text Version:\", tensorflow_text.__version__)\n",
        "print(\"Numpy Version:\", np.__version__)\n",
        "print(\"SQLite3 Version:\", sqlite3.version)\n"
      ],
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBqIST5hFTDS",
        "outputId": "569a724a-aeb4-490c-aadc-901ecfed5716"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
          "text": [
            "PyTorch Version: 2.5.1+cu124\n",
            "SentencePiece Version: 0.2.0\n",
            "TensorFlow Version: 2.18.0\n",
            "TensorFlow Hub Version: 0.16.1\n",
            "TensorFlow Text Version: 2.18.1\n",
            "Numpy Version: 1.26.4\n",
            "SQLite3 Version: 2.6.0\n"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "# List versions of the imports\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"SentencePiece Version:\", sentencepiece.__version__)\n",
        "print(\"TensorFlow Version:\", tensorflow.__version__)\n",
        "print(\"TensorFlow Hub Version:\", tensorflow_hub.__version__)\n",
        "print(\"TensorFlow Text Version:\", tensorflow_text.__version__)\n",
        "print(\"Numpy Version:\", np.__version__)\n",
        "print(\"SQLite3 Version:\", sqlite3.version)\n"
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
<<<<<<< HEAD
        "id": "QFfFp7kox6fb",
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
        "outputId": "ae8b4830-d429-4ef1-a4ec-5cf8c7ad655b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be3f9f31-9e8c-4d20-a39e-8ebf2ef32f9f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be3f9f31-9e8c-4d20-a39e-8ebf2ef32f9f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving symbipredict.csv to symbipredict.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "_jFTJ6DhqQ-l",
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
        "outputId": "9fb9c2a0-3339-4745-ee81-83f604bcce3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                                                                                                                                       <<<<<<< HEAD\n",
            "Disease          Symptom_1 Symptom_2            Symptom_3            Symptom_4           Symptom_5 Symptom_6 Symptom_7 Symptom_8 Symptom_9 Symptom_1 Symptom_11 Symptom_12 Symptom_13 Symptom_14 Symptom_15 Symptom_16   Symptom_17\n",
            "Fungal Infection itching   skin_rash            nodal_skin_eruptions dischromic _patches NaN       NaN       NaN       NaN       NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN                 NaN\n",
            "                 skin_rash nodal_skin_eruptions dischromic _patches  NaN                 NaN       NaN       NaN       NaN       NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN                 NaN\n",
            "                 itching   nodal_skin_eruptions dischromic _patches  NaN                 NaN       NaN       NaN       NaN       NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN                 NaN\n",
            "                           skin_rash            dischromic _patches  NaN                 NaN       NaN       NaN       NaN       NaN       NaN       NaN        NaN        NaN        NaN        NaN        NaN                 NaN\n"
          ]
        }
      ],
      "source": [
        "#  Read the .csv using pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data, specifying error handling and potential delimiter\n",
        "disease_data = pd.read_csv('symbipredict.csv', on_bad_lines='skip', delimiter=',') # Added on_bad_lines='skip' and delimiter=','\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(disease_data.head())"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 6,
=======
      "source": [
        "# Version of pandas\n",
        "print(pd.__version__)"
      ],
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3fEw-HqF_DI",
        "outputId": "2cb99f30-75a7-4c16-dbe8-9ecb0ff8ffd0"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
          "text": [
            "2.2.2\n"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "# Version of pandas\n",
        "print(pd.__version__)"
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p4GiC3qvsT1K"
      },
      "outputs": [],
      "source": [
        "# After loading the data, it is necessary to combine the symptom_columns into a single column\n",
        "symptom_columns = [col for col in disease_data.columns if col != 'Disease']\n",
        "disease_data['Processed_Symptoms'] = disease_data[symptom_columns].apply(lambda x: ' '.join(x.astype(str)), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4jEvV2GdmEI"
      },
      "source": [
        "In the section below, we import the necessary libraries and dictionaries in order to build our NLTK model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< HEAD
        "id": "JWaKd3Drusfc",
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
        "outputId": "f3fcfaf7-2c1e-468b-e39a-59a4e3c7ed3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries starting with nltk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 9,
=======
      "source": [
        "# Version of nltk\n",
        "print(nltk.__version__)"
      ],
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_TK9YSvFm9q",
        "outputId": "2da99eba-2f03-4434-f5d2-1659eb71e829"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
          "text": [
            "3.9.1\n"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "# Version of nltk\n",
        "print(nltk.__version__)"
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4yaBUKy4pb2"
      },
      "source": [
        "In the section below, we are defining how we want to use our dataset(s).  We want patients to input their symptoms, then we associate them to key words from our dataset(s).  This is our preprocessing of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s1Qbiwssm0Ys"
      },
      "outputs": [],
      "source": [
        "# Define the prepocessing of the data\n",
        "def preprocess_symptoms(symptom_text):\n",
        "    tokens = word_tokenize(symptom_text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [w for w in tokens if not w in stop_words and w.isalnum()]\n",
        "    return ' '.join(filtered_tokens)\n",
        "\n",
        "# Example synonym dictionary (this can be expanded)\n",
        "synonym_dict = {\n",
        "    'fever': ['fever', 'pyrexia'],\n",
        "    'headache': ['headache', 'migraine', 'cephalalgia'],\n",
        "    'nausea': ['nausea', 'queasiness', 'sickness'],\n",
        "    'vomiting': ['vomiting', 'throwing up', 'emesis'],\n",
        "    'sore throat': ['sore throat', 'pharyngitis', 'throat pain']\n",
        "}\n",
        "\n",
        "def expand_keywords(keywords):\n",
        "    expanded_keywords = set()\n",
        "    for keyword in keywords:\n",
        "        if keyword in synonym_dict:\n",
        "            expanded_keywords.update(synonym_dict[keyword])\n",
        "        else:\n",
        "            expanded_keywords.add(keyword)\n",
        "    return list(expanded_keywords)\n",
        "\n",
        "def extract_keywords(patient_feedback):\n",
        "    tokens = word_tokenize(patient_feedback.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [w for w in tokens if not w in stop_words and w.isalnum()]\n",
        "    pos_tags = nltk.pos_tag(filtered_tokens)\n",
        "    keywords = [word for word, pos in pos_tags if pos.startswith('NN') or pos.startswith('JJ') or pos.startswith('VB')]\n",
        "    return keywords\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66d7zFr_5FLf"
      },
      "source": [
        "In the section(s) below, the application will read the patient input and suggest diagnosis.  This is our vectorizing process.  Once we vectorize, we run the gradio app, which generates an input cell for patient data, and an output cell for possible diagnoses.  We chose to use Transformers (vectorizing) via TF-IDF becausee it performed better with gradio.  SpaCy and gradio had constant version conflicts, which caused our application to break, so we switched to TF-IDF.\n",
        "\n",
        "NOTE:  We are allowing for a possible 5 diagnoses.  Many symptoms cross over numerous diagnoses.  For now, our app is merely suggesting some possible diagnoses.  Our future model will be more precise.  More data is needed to establish that kind of precision.  Given these challenges and the short runway of time we had to develop this application, we decided to put in a patient feedback loop in our gradio application called flagging.  This allows the patient to tell us if the proposed diagnoses are \"Correct\", \"Incorrect\", \"Needs Improvement\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "814xz1CYvFfm"
      },
      "outputs": [],
      "source": [
        "# Install needed tools to build and run the gradio interface\n",
        "import os\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Use the preloaded disease_data\n",
        "def extract_keywords(feedback):\n",
        "    # Placeholder for actual keyword extraction logic\n",
        "    return feedback.split()\n"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 12,
=======
      "source": [
        "# Version of gradio\n",
        "print(gr.__version__)"
      ],
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-oOtrX9FvbV",
        "outputId": "e12aa9b0-b8a3-4d8d-eb02-1fcfe78d5166"
      },
<<<<<<< HEAD
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
=======
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
          "text": [
            "5.16.0\n"
          ]
        }
<<<<<<< HEAD
      ],
      "source": [
        "# Version of gradio\n",
        "print(gr.__version__)"
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 13,
      "metadata": {
        "id": "YWIw55cB0BwV"
      },
      "outputs": [],
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "source": [
        "# Breaking this down into smaller segments.  This piece suggests diagnoses\n",
        "def suggest_diagnosis_tfidf(patient_feedback):\n",
        "    print(\"Patient Feedback:\", patient_feedback)\n",
        "    keywords = extract_keywords(patient_feedback)\n",
        "    print(\"Keywords:\", keywords)\n",
        "    expanded_keywords = expand_keywords(keywords)\n",
        "    print(\"Expanded Keywords:\", expanded_keywords)\n",
        "\n",
        "    processed_feedback = ' '.join(expanded_keywords)\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    symptom_matrix = vectorizer.fit_transform(disease_data['Processed_Symptoms'])\n",
        "    feedback_vector = vectorizer.transform([processed_feedback])\n",
        "    similarities = cosine_similarity(feedback_vector, symptom_matrix)\n",
        "    sorted_indices = similarities.argsort()[0][::-1]\n",
        "    print(\"Sorted Indices:\", sorted_indices)\n",
        "\n",
        "    possible_diagnoses = []\n",
        "    added_diseases = set()  # To track added diagnoses and avoid duplicates\n",
        "    for idx in sorted_indices:\n",
        "        disease_name = disease_data.loc[idx, 'Disease']\n",
        "        if disease_name not in added_diseases:\n",
        "            possible_diagnoses.append(disease_name)\n",
        "            added_diseases.add(disease_name)\n",
        "\n",
        "    if not possible_diagnoses:\n",
        "        possible_diagnoses = [\"Unable to determine a diagnosis based on the provided information.\"]\n",
        "\n",
        "    print(\"Possible Diagnoses:\", possible_diagnoses[:5])\n",
        "    return possible_diagnoses[:5]\n"
<<<<<<< HEAD
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-D0bIH00zj2",
        "outputId": "7319629e-dcec-4d62-f6b0-eb9e4fe16c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flagged data should be saved in: /content/custom_flagged_data\n"
          ]
        }
      ],
=======
      ],
      "metadata": {
        "id": "YWIw55cB0BwV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "source": [
        "# Check that flagging directory exists and accessible\n",
        "custom_flagged_dir = 'custom_flagged_data'\n",
        "if not os.path.exists(custom_flagged_dir):\n",
        "    os.makedirs(custom_flagged_dir)\n",
        "print(f\"Flagged data should be saved in: {os.path.abspath(custom_flagged_dir)}\")\n"
<<<<<<< HEAD
=======
      ],
      "metadata": {
        "id": "D-D0bIH00zj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7319629e-dcec-4d62-f6b0-eb9e4fe16c09"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flagged data should be saved in: /content/custom_flagged_data\n"
          ]
        }
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "7BEILyUA0-9w",
        "outputId": "ad489dc4-b9d8-4249-aa0d-dc6682a9b2b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0ac621b911f5e13063.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0ac621b911f5e13063.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
=======
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      "source": [
        "# Run gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=suggest_diagnosis_tfidf,\n",
        "    inputs=gr.Textbox(lines=5, placeholder=\"Describe your symptoms...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Symptom Checker\",\n",
        "    description=\"Enter your symptoms, and we'll suggest possible diagnoses.\",\n",
        "    flagging_options=[\"Correct\", \"Incorrect\", \"Needs Improvement\"],\n",
        "    flagging_dir='custom_flagged_data'\n",
        ")\n",
        "\n",
        "iface.launch(share=True)\n"
<<<<<<< HEAD
=======
      ],
      "metadata": {
        "id": "7BEILyUA0-9w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "ad489dc4-b9d8-4249-aa0d-dc6682a9b2b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0ac621b911f5e13063.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0ac621b911f5e13063.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
>>>>>>> 7d84e816ba4889c4460789cabf5570e8a77e2a21
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmL9sN5aw5OQ"
      },
      "source": [
        "**For Future Development**\n",
        " Our future development will consist of expanding our application to include treatment recommendations for the diagnoses output.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
